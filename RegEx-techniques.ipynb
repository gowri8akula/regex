{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##A Regular Expression (RegEx) is a sequence of characters that defines a search pattern.Regular expressions (regex) are essentially text patterns that you can use to automate searching through and replacing elements within strings of text. This can make cleaning and working with text-based data sets much easier, saving you the trouble of having to search through mountains of text by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##basic requirements - basic familiarity with key Python concepts like if-else statements, while and for loops, etc.\n",
    "##At the end we will learn - introduction to how regex can be used in concert with pandas to work with large text corpuses\n",
    "##(corpus means a data set of text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###practical applications of regex:Data Validation,Text Search and Extraction,URL Matching and Routing,Data Cleaning and Transformation,Text Manipulation,\n",
    "Log Analysis,Programming Language Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The Impact of Dirty Data on Analysis\n",
    "Dirty data negatively impacts analysis. Common data quality issues that regex helps address:\n",
    "\n",
    "Missing values Duplicate records Inconsistent formatting (dates, names) Invalid entries\n",
    "Without cleaning, these issues can skew results.\n",
    "\n",
    "Advantages of Regex for Data Cleaning\n",
    "Key regex benefits for data cleaning:\n",
    "\n",
    "Flexible pattern matching Powerful search and replace Automation at scale Language agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result found\n"
     ]
    }
   ],
   "source": [
    "pattern = '^a...s$'\n",
    "test_string = 'abyss'\n",
    "result = re.match(pattern,test_string)\n",
    "if result:\n",
    "    print(\"result found\")\n",
    "else:\n",
    "    print(\"no result found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search successful:{test_string}\n"
     ]
    }
   ],
   "source": [
    "pattern = '^a...s$'\n",
    "test_string = 'abyss'\n",
    "result = re.match(pattern, test_string)\n",
    "\n",
    "if result:\n",
    "  print('Search successful:{test_string}')\n",
    "else:\n",
    "  print('Search unsuccessful:{test_string}')\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search successful:abyss\n"
     ]
    }
   ],
   "source": [
    "pattern = '^a...s$'\n",
    "test_string = 'abyss'\n",
    "result = re.match(pattern, test_string)\n",
    "\n",
    "if result:\n",
    "  print(f'Search successful:{test_string}')\n",
    "else:\n",
    "  print(f'Search unsuccessful:{test_string}')\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abyss\n"
     ]
    }
   ],
   "source": [
    "regex = '^ab'\n",
    "strings = 'abyss'\n",
    "result = re.match(regex,strings)\n",
    "\n",
    "if result:\n",
    "    print(f'{strings}')\n",
    "else:\n",
    "    print(f'{strings}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-6c32629e5e6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstrings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'match found:{result}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mmatch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \"\"\"Try to apply the pattern at the start of the string, returning\n\u001b[0;32m    172\u001b[0m     a Match object, or None if no match was found.\"\"\"\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfullmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "regex = r'^ab'\n",
    "strings = ['abyss','abs','alias','an abacus']\n",
    "\n",
    "for string in strings:\n",
    "    if re.match(regex,strings):\n",
    "        print('match found:{result}')\n",
    "    else:\n",
    "        print('match not found:{result}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: abyss\n",
      "Matched: abs\n",
      "Not matched: alias\n",
      "Not matched: an abacus\n"
     ]
    }
   ],
   "source": [
    "regex = r'^ab'\n",
    "strings = ['abyss','abs','alias','an abacus']\n",
    "        \n",
    "for string in strings:\n",
    "    if re.match(regex, string):\n",
    "        print(f'Matched: {string}')\n",
    "    else:\n",
    "        print(f'Not matched: {string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: abyss\n",
      "Not matched: abs\n",
      "Matched: alias\n",
      "Not matched: an abacus\n"
     ]
    }
   ],
   "source": [
    "regex = r'^a...s$'\n",
    "strings = ['abyss','abs','alias','an abacus']\n",
    "        \n",
    "for string in strings:\n",
    "    if re.match(regex, string):\n",
    "        print(f'Matched: {string}')\n",
    "    else:\n",
    "        print(f'Not matched: {string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(21, 25), match='Data'>\n"
     ]
    }
   ],
   "source": [
    "s = \"We are looking for a Data Scientist with 3+ years of experience in Python and a Master's degree\"\n",
    "match =re.search(r'Data',s)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Index: 21\n",
      "End Index: 25\n"
     ]
    }
   ],
   "source": [
    "s = \"We are looking for a Data Scientist with 3+ years of experience in Python and a Master's degree\"\n",
    "match =re.search(r'Data',s)\n",
    "print('Start Index:',match.start())\n",
    "print('End Index:',match.end())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='W'>\n",
      "<re.Match object; span=(95, 95), match=''>\n"
     ]
    }
   ],
   "source": [
    "s = \"We are looking for a Data Scientist with 3+ years of experience in Python and a Master's degree\"\n",
    "\n",
    "# without using' .' Matches any character except newline\n",
    "match = re.search(r'.', s)\n",
    "print(match)\n",
    "\n",
    "# using '$' matches the end\n",
    "match = re.search(r'$', s)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: The quick brown fox\n",
      "Matched: The lazy dog\n",
      "Not matched: A quick brown fox\n"
     ]
    }
   ],
   "source": [
    "#Caret (^) symbol matches the beginning of the string i.e. checks whether the string starts \n",
    "#with the given character(s) or not.\n",
    "regex = r'^The'\n",
    "strings = ['The quick brown fox', 'The lazy dog', 'A quick brown fox']\n",
    "for string in strings:\n",
    "    if re.match(regex, string):\n",
    "        print(f'Matched: {string}')\n",
    "    else:\n",
    "        print(f'Not matched: {string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found!\n"
     ]
    }
   ],
   "source": [
    "#The dot (.) in the pattern represents any character\n",
    "string = \"Implementing Regex techniques to analyze job descriptions is a powerful way\"\n",
    "pattern = r\"analyze.job\"\n",
    "\n",
    "match = re.search(pattern, string)\n",
    "if match:\n",
    "    print(\"Match found!\")\n",
    "else:\n",
    "    print(\"Match not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match not found.\n"
     ]
    }
   ],
   "source": [
    "#regular expression to check if the string ends with “World!”\n",
    "#Dollar($) symbol matches the end of the string\n",
    "\n",
    "string = \"Hello World! this is my world\"\n",
    "pattern = r\"World!$\"\n",
    "\n",
    "match = re.search(pattern, string)\n",
    "if match:\n",
    "    print(\"Match found!\")\n",
    "else:\n",
    "    print(\"Match not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found!\n"
     ]
    }
   ],
   "source": [
    "#regular expression to check if the string ends with “World!”\n",
    "#Dollar($) symbol matches the end of the string\n",
    "\n",
    "string = \"Hello World! this is my World!\"\n",
    "pattern = r\"World!$\"\n",
    "\n",
    "match = re.search(pattern, string)\n",
    "if match:\n",
    "    print(\"Match found!\")\n",
    "else:\n",
    "    print(\"Match not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Scientist', '3+ years', 'Python', \"Master's\"]\n"
     ]
    }
   ],
   "source": [
    "job_description = \"We are looking for a Data Scientist with 3+ years of experience in Python and a Master's degree.\"\n",
    "regex_pattern = r'\\b(?:Data Scientist|Python|Master\\'s|3\\+ years)\\b'\n",
    "matches = re.findall(regex_pattern, job_description)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Scientist', '3+ years', 'Python', \"Master's\"]\n"
     ]
    }
   ],
   "source": [
    "job_description = \"We are looking for a Data Scientist with 3+ years of experience in Python and a Master's degree.\"\n",
    "regex_pattern = r'\\b(?:Data Scientist|Python|Master\\'s|3\\+ years)\\b'\n",
    "matches = re.findall(regex_pattern, job_description)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', 'a', 'e', 'l', 'k', 'i', 'g', 'f', 'a', 'a', 'a', 'c', 'i', 'e', 'i', 'i', 'h', 'e', 'a', 'f', 'e', 'e', 'i', 'e', 'c', 'e', 'i', 'h', 'a', 'd', 'a', 'a', 'e', 'd', 'e', 'g', 'e', 'e']\n"
     ]
    }
   ],
   "source": [
    "# to find all the characters in the string that fall within the range of ‘a’ to ‘m’.\n",
    "s = \"We are looking for a Data Scientist with 3+ years of experience in Python and a Master's degree\"\n",
    "regex = \"[a-m]\"\n",
    "match = re.findall(regex,s)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', ' ', 'r', ' ', 'o', 'o', 'n', ' ', 'o', 'r', ' ', ' ', 'D', 't', ' ', 'S', 'n', 't', 's', 't', ' ', 'w', 't', ' ', '3', '+', ' ', 'y', 'r', 's', ' ', 'o', ' ', 'x', 'p', 'r', 'n', ' ', 'n', ' ', 'P', 'y', 't', 'o', 'n', ' ', 'n', ' ', ' ', 'M', 's', 't', 'r', \"'\", 's', ' ', 'r']\n"
     ]
    }
   ],
   "source": [
    "# in below code except from a to m, remaning all is printed\n",
    "s = \"We are looking for a Data Scientist with 3+ years of experience in Python and a Master's degree\"\n",
    "regex = \"[^a-m]\"\n",
    "match = re.findall(regex,s)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##test case on job descriptions to identify key requirements##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Words/Phrases:\n",
      "Data Scientist\n",
      "3+ years\n",
      "Python\n",
      "Master's\n"
     ]
    }
   ],
   "source": [
    "JD = \"Under direct supervision, provides remote technical support services to external and internal users of Landmark environment and applications on basic/routine issues via telephone, email and electronic channels while adhering to Customer Support operational processes and best practices.\"\n",
    "\" Resolves the end user&aposs service request by applying established problem solving techniques including trouble shooting, data quality review, replicating the end user&aposs workflow, understanding how the software is functioning and proposing solutions that allow the end user to achieve their objectives.\"\n",
    "\" Service requests are limited to basic questions regarding installations, configuration, data formatting and application functionality/workflows. Escalates all complex or novel issues to higher level Support Analysts as needed.\"\n",
    "\" The nature of the support services provided requires knowledge of the domain science and knowledge of one to few software applications used within the domain.\"\n",
    "\"Knowledge of domain software applications is acquired through structured training, self-guided learning, and on-the-job experiences. Requires an undergraduate degree.\"\n",
    "\"No previous experience is required. Concentration in geoscience, engineering, or computer science is preferred.\"\n",
    " \n",
    "# Define a regex pattern to extract relevant words/phrases\n",
    "# This pattern looks for skills, qualifications, and experience levels.\n",
    "regex = r'\\b(Data Scientist|Python|R|SQL|Master\\'s degree|Computer Science|machine learning|Tableau|3\\+ years)\\b'\n",
    "\n",
    "# Find all matches in the job description\n",
    "matches = re.findall(regex_pattern, job_description)\n",
    "\n",
    "# Print the extracted words\n",
    "print(\"Extracted Words/Phrases:\")\n",
    "for match in matches:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetitive Words and Their Counts:\n",
      "support: 2\n",
      "to: 2\n",
      "and: 4\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "JD = \"Under direct supervision, provides remote technical support services to external and internal users of Landmark environment and applications on basic/routine issues via telephone, email and electronic channels while adhering to Customer Support operational processes and best practices.\"\n",
    "\" Resolves the end user&aposs service request by applying established problem solving techniques including trouble shooting, data quality review, replicating the end user&aposs workflow, understanding how the software is functioning and proposing solutions that allow the end user to achieve their objectives.\"\n",
    "\" Service requests are limited to basic questions regarding installations, configuration, data formatting and application functionality/workflows. Escalates all complex or novel issues to higher level Support Analysts as needed.\"\n",
    "\" The nature of the support services provided requires knowledge of the domain science and knowledge of one to few software applications used within the domain.\"\n",
    "\"Knowledge of domain software applications is acquired through structured training, self-guided learning, and on-the-job experiences. Requires an undergraduate degree.\"\n",
    "\"No previous experience is required. Concentration in geoscience, engineering, or computer science is preferred.\"\n",
    "\n",
    "# Define a regex pattern to find words (case insensitive)\n",
    "regex = r'\\b\\w+\\b'  # Matches any word\n",
    "\n",
    "# Find all words in the text using regex\n",
    "words = re.findall(regex, JD.lower())  # Convert to lowercase for uniform counting\n",
    "\n",
    "# Count occurrences of each word\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Print the repetitive words and their counts\n",
    "print(\"Repetitive Words and Their Counts:\")\n",
    "for word, count in word_counts.items():\n",
    "    if count > 1:  # Only display words that appear more than once\n",
    "        print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##r'\\b\\w+\\b': This pattern matches any whole word (defined as a sequence of word characters).\n",
    "##\\b: Asserts a word boundary, ensuring whole words are matched.\n",
    "##\\w+: Matches one or more word characters (letters, digits, underscores).\n",
    "##Counter(words): Counts the occurrences of each word in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  now print unique words from JD##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Words:\n",
      "adhering\n",
      "and\n",
      "applications\n",
      "basic\n",
      "best\n",
      "channels\n",
      "customer\n",
      "direct\n",
      "electronic\n",
      "email\n",
      "environment\n",
      "external\n",
      "internal\n",
      "issues\n",
      "landmark\n",
      "of\n",
      "on\n",
      "operational\n",
      "practices\n",
      "processes\n",
      "provides\n",
      "remote\n",
      "routine\n",
      "services\n",
      "supervision\n",
      "support\n",
      "technical\n",
      "telephone\n",
      "to\n",
      "under\n",
      "users\n",
      "via\n",
      "while\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "JD = \"Under direct supervision, provides remote technical support services to external and internal users of Landmark environment and applications on basic/routine issues via telephone, email and electronic channels while adhering to Customer Support operational processes and best practices.\"\n",
    "\" Resolves the end user&aposs service request by applying established problem solving techniques including trouble shooting, data quality review, replicating the end user&aposs workflow, understanding how the software is functioning and proposing solutions that allow the end user to achieve their objectives.\"\n",
    "\" Service requests are limited to basic questions regarding installations, configuration, data formatting and application functionality/workflows. Escalates all complex or novel issues to higher level Support Analysts as needed.\"\n",
    "\" The nature of the support services provided requires knowledge of the domain science and knowledge of one to few software applications used within the domain.\"\n",
    "\"Knowledge of domain software applications is acquired through structured training, self-guided learning, and on-the-job experiences. Requires an undergraduate degree.\"\n",
    "\"No previous experience is required. Concentration in geoscience, engineering, or computer science is preferred.\"\n",
    "\n",
    "# Define a regex pattern to find words (case insensitive)\n",
    "regex = r'\\b\\w+\\b'  # Matches any word\n",
    "\n",
    "# Find all words in the text using regex\n",
    "words = re.findall(regex, JD.lower())  # Convert to lowercase for uniform counting\n",
    "\n",
    "# Use a set to find unique words\n",
    "unique_words = set(words)\n",
    "\n",
    "# Print the unique words\n",
    "print(\"Unique Words:\")\n",
    "for word in sorted(unique_words):  # Sort for better readability\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##practice on random questions##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1#Create a definition function without arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "def python_def_keyword():\n",
    "    print (\"hello\")\n",
    "python_def_keyword()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtraction of  90  and  40  is =  50\n"
     ]
    }
   ],
   "source": [
    "#2#Create a def function to find the subtraction of two numbers.\n",
    "\n",
    "#function for subtraction of 2 numbers\n",
    "def python_def_subnumbers(x,y):\n",
    "    return (x-y)\n",
    "#main code\n",
    "a=90\n",
    "b=40\n",
    "\n",
    "#finding subtraction\n",
    "result = python_def_subnumbers(a,b)\n",
    "\n",
    "print(\"subtraction of \", a, \" and \", b, \" is = \", result)\n",
    "\n",
    "#print(\"sub of\",a, \"and\", b, \"is =\" result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'hello123': Valid\n",
      "'hello world!': Invalid\n",
      "'validstring123': Valid\n",
      "'123456': Valid\n",
      "'invalid@chars': Invalid\n",
      "'': Invalid\n"
     ]
    }
   ],
   "source": [
    "##1. Write a Python program to check that a string contains only a certain set of characters (in this case a-z, A-Z and 0-9).\n",
    "\n",
    "import re\n",
    "\n",
    "def is_valid_string(s):\n",
    "# Define the regex pattern for allowed characters (a-z, A-Z, 0-9)\n",
    "    pattern = r'^[a-zA-Z0-9]+$'\n",
    "\n",
    "# Use re.match to check if the entire string matches the pattern\n",
    "    return re.match(pattern, s)is not None\n",
    "\n",
    "#test cases\n",
    "test_string=[\"hello123\",\"hello world!\",\"validstring123\",\"123456\",\"invalid@chars\",\"\",]\n",
    "\n",
    "##test_strings = [\n",
    "## \"Hello123\",  # Valid\n",
    "##    \"Hello World!\",  # Invalid (space and punctuation)\n",
    "##  \"ValidString456\",  # Valid\n",
    "##    \"123456\",  # Valid\n",
    "##    \"invalid@chars\",  # Invalid (special character)\n",
    "##    \"\",  # Invalid (empty string)\n",
    "##]\n",
    "\n",
    "# Check each test string\n",
    "for test in test_string:\n",
    "    result = is_valid_string(test)\n",
    "    print(f\"'{test}': {'Valid' if result else 'Invalid'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##2. Write a Python program that matches a string that has an a followed by zero or more b's.\n",
    "\n",
    "import re\n",
    "\n",
    "def is_valid_string(s):\n",
    "## Define the regex pattern for \"a\" followed by zero or more \"b\"s\n",
    "    pattern = r'^a(b*)'\n",
    "    \n",
    "## use re.match to check if the string matches the pattern\n",
    "    match = re.match(pattern, s)\n",
    "    \n",
    "    if match:\n",
    "        return f\"matched:'{match.group()}' '{with match.group(1)}' (zero or more 'b' s)\"\n",
    "    else:\n",
    "        retunr \"no match\"\n",
    "        \n",
    "#test cases\n",
    "    test_strings: [\"a\",\"ab\",\"abb\",\"xyz\",\"ab2\",\"aabb\",\"a b\"]\n",
    "        \n",
    "# Check each test string\n",
    "for test in test_strings:\n",
    "    result = match_string(test)\n",
    "    print(f\"'{test}': {result}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now trying regex on some JDs##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##fh = file handle, and here we are setting file to redad only, and reading it.\n",
    "the directory precede with r converts a string into a raw string,which helps to avoid conflicts\n",
    "caused by some machines read characters such as backslashes in directory paths on windows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh= open(r\"jobs-JDs.txt\",\"r\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "two arguments in the form of re.findall(pattern, string)\n",
    "Here, pattern represents the substring we want to find, \n",
    "and string represents the main string we want to find it in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'txt', 'jobs', 'JDs'}\n"
     ]
    }
   ],
   "source": [
    "regex = r'\\b\\w+\\b'\n",
    "words = re.findall(regex, \"jobs-JDs.txt\")\n",
    "unique_words = set(words)\n",
    "print(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_words:\n",
      "JDs\n",
      "jobs\n",
      "txt\n"
     ]
    }
   ],
   "source": [
    "regex = r'\\b\\w+\\b'\n",
    "words = re.findall(regex, \"jobs-JDs.txt\")\n",
    "unique_words = set(words)\n",
    "print(\"unique_words:\")\n",
    "for word in sorted(unique_words):  # Sort for better readability\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w matches alphanumeric characters, which means a-z, A-Z, and 0-9. It also matches the underscore, _, and the dash, -.\n",
    "d matches digits, which means 0-9.\n",
    "s matches whitespace characters, which include the tab, new line, carriage return, and space characters.\n",
    "S matches non-whitespace characters.\n",
    ". matches any character except the new line character n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skills\n",
      "skills\n",
      "skills\n",
      "skills\n",
      "skills\n",
      "skills\n",
      "skille\n",
      "skills\n",
      "skills\n",
      "skills\n",
      "skills\n",
      "skills\n",
      "skills\n",
      "skills\n"
     ]
    }
   ],
   "source": [
    "for line in re.findall(\"skill.\",fh):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skills, written and verbal.', 'skills.', 'skills', 'skills (ability to work and communicate with different departments/functions e.g. subsurface, offshore, operations, and external stakeholders).', 'skills, capacity and motivation to deliver in a timely manner.', 'skills.', 'skilled Data Analyst to join our dynamic team. In this role, you will work with large volumes of data to provide valuable business insights, supporting our Analytics team in making data-driven decisions. You will leverage tools like SQL, Tableau, or Power BI to conduct detailed analyses and deliver comprehensive reports that will guide performance assessment and process optimization across the business.', 'skills with an analytical mindset.', 'skills and the ability to explain analytical concepts to a non-technical audience.', 'skills, data manipulation capabilities and business acumen.', 'skills. Ability to lead large organizations through influence.', 'skills, including a proven ability to quickly analyze and develop data models, identify patterns, business rules, workflows and interfaces', 'skills (and advanced Microsoft Word and PowerPoint experience) to communicate effectively across groups and levels in an effective and collaborative manner ', 'skills; self-initiated, highly motivated, flexible, and able to work effectively both independently and collaboratively in a multicultural team environment; work productively on multiple tasks under pressure with competing and inflexible deadlines; distill complex data and information requirements from a wide spectrum of requestors into valuable end-products; maintaining composure in an environment of constant quality improvement; and ability to exercise good judgment and discretion when navigating complex situations, handling confidential information, and processing personally identifiable data ']\n"
     ]
    }
   ],
   "source": [
    "match = re.findall(\"skill.*\", fh)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here above and below are same but printed line wise in below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skills, written and verbal.\n",
      "skills.\n",
      "skills\n",
      "skills (ability to work and communicate with different departments/functions e.g. subsurface, offshore, operations, and external stakeholders).\n",
      "skills, capacity and motivation to deliver in a timely manner.\n",
      "skills.\n",
      "skilled Data Analyst to join our dynamic team. In this role, you will work with large volumes of data to provide valuable business insights, supporting our Analytics team in making data-driven decisions. You will leverage tools like SQL, Tableau, or Power BI to conduct detailed analyses and deliver comprehensive reports that will guide performance assessment and process optimization across the business.\n",
      "skills with an analytical mindset.\n",
      "skills and the ability to explain analytical concepts to a non-technical audience.\n",
      "skills, data manipulation capabilities and business acumen.\n",
      "skills. Ability to lead large organizations through influence.\n",
      "skills, including a proven ability to quickly analyze and develop data models, identify patterns, business rules, workflows and interfaces\n",
      "skills (and advanced Microsoft Word and PowerPoint experience) to communicate effectively across groups and levels in an effective and collaborative manner \n",
      "skills; self-initiated, highly motivated, flexible, and able to work effectively both independently and collaboratively in a multicultural team environment; work productively on multiple tasks under pressure with competing and inflexible deadlines; distill complex data and information requirements from a wide spectrum of requestors into valuable end-products; maintaining composure in an environment of constant quality improvement; and ability to exercise good judgment and discretion when navigating complex situations, handling confidential information, and processing personally identifiable data \n"
     ]
    }
   ],
   "source": [
    "fh= open(r\"jobs-JDs.txt\",\"r\").read()\n",
    "for line in re.findall(\"skill.*\",fh):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skills, written and verbal.']\n",
      "['skills.']\n",
      "['skills']\n",
      "['skills (ability to work and communicate with different departments/functions e.g. subsurface, offshore, operations, and external stakeholders).']\n",
      "['skills, capacity and motivation to deliver in a timely manner.']\n",
      "['skills.']\n",
      "['skilled Data Analyst to join our dynamic team. In this role, you will work with large volumes of data to provide valuable business insights, supporting our Analytics team in making data-driven decisions. You will leverage tools like SQL, Tableau, or Power BI to conduct detailed analyses and deliver comprehensive reports that will guide performance assessment and process optimization across the business.']\n",
      "['skills with an analytical mindset.']\n",
      "['skills and the ability to explain analytical concepts to a non-technical audience.']\n",
      "['skills, data manipulation capabilities and business acumen.']\n",
      "['skills. Ability to lead large organizations through influence.']\n",
      "['skills, including a proven ability to quickly analyze and develop data models, identify patterns, business rules, workflows and interfaces']\n",
      "['skills (and advanced Microsoft Word and PowerPoint experience) to communicate effectively across groups and levels in an effective and collaborative manner ']\n",
      "['skills; self-initiated, highly motivated, flexible, and able to work effectively both independently and collaboratively in a multicultural team environment; work productively on multiple tasks under pressure with competing and inflexible deadlines; distill complex data and information requirements from a wide spectrum of requestors into valuable end-products; maintaining composure in an environment of constant quality improvement; and ability to exercise good judgment and discretion when navigating complex situations, handling confidential information, and processing personally identifiable data ']\n"
     ]
    }
   ],
   "source": [
    "match = re.findall(\"skill.*\",fh)\n",
    "\n",
    "for line in match:\n",
    "    print(re.findall(\"skill.*\", line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Words:\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "7\n",
      "a\n",
      "ability\n",
      "able\n",
      "about\n",
      "above\n",
      "abu\n",
      "academia\n",
      "academic\n",
      "acceptance\n",
      "account\n",
      "accountabilities\n",
      "accountability\n",
      "accounting\n",
      "accounts\n",
      "accuracy\n",
      "accurate\n",
      "acquisition\n",
      "across\n",
      "actionable\n",
      "active\n",
      "activities\n",
      "activity\n",
      "acumen\n",
      "ad\n",
      "added\n",
      "adding\n",
      "additional\n",
      "address\n",
      "adekâ\n",
      "adhere\n",
      "administration\n",
      "adobe\n",
      "advanced\n",
      "advantage\n",
      "aems\n",
      "agc\n",
      "agile\n",
      "agreed\n",
      "ai\n",
      "algorithms\n",
      "all\n",
      "also\n",
      "an\n",
      "analyses\n",
      "analysis\n",
      "analyst\n",
      "analysts\n",
      "analytical\n",
      "analytics\n",
      "analyze\n",
      "analyzing\n",
      "and\n",
      "answers\n",
      "apache\n",
      "api\n",
      "apis\n",
      "applications\n",
      "applied\n",
      "applying\n",
      "approaches\n",
      "appropriately\n",
      "approx\n",
      "arab\n",
      "architect\n",
      "architecture\n",
      "are\n",
      "arrive\n",
      "arts\n",
      "as\n",
      "asana\n",
      "assess\n",
      "assesses\n",
      "assessment\n",
      "assets\n",
      "assist\n",
      "assistance\n",
      "associate\n",
      "assurance\n",
      "assure\n",
      "at\n",
      "atmosphere\n",
      "attention\n",
      "attire\n",
      "audience\n",
      "audits\n",
      "automate\n",
      "automated\n",
      "automation\n",
      "autonomously\n",
      "available\n",
      "aws\n",
      "azure\n",
      "aâ\n",
      "b\n",
      "baccalaureate\n",
      "bachelors\n",
      "bachelorâ\n",
      "backbone\n",
      "backend\n",
      "based\n",
      "basic\n",
      "be\n",
      "believes\n",
      "belonging\n",
      "benchmarking\n",
      "best\n",
      "between\n",
      "bi\n",
      "block\n",
      "both\n",
      "bp\n",
      "bridge\n",
      "broad\n",
      "broader\n",
      "build\n",
      "builder\n",
      "building\n",
      "business\n",
      "by\n",
      "c\n",
      "call\n",
      "campuses\n",
      "can\n",
      "candidate\n",
      "canva\n",
      "capabilities\n",
      "capable\n",
      "capacity\n",
      "capex\n",
      "carrying\n",
      "case\n",
      "cases\n",
      "casual\n",
      "center\n",
      "centers\n",
      "certified\n",
      "cgpa\n",
      "challenges\n",
      "chance\n",
      "checking\n",
      "cheds\n",
      "clarification\n",
      "clarity\n",
      "cleanse\n",
      "clearly\n",
      "client\n",
      "clients\n",
      "closely\n",
      "cloud\n",
      "code\n",
      "coding\n",
      "collaborate\n",
      "collaboration\n",
      "collaborative\n",
      "collaboratively\n",
      "collibra\n",
      "com\n",
      "combining\n",
      "command\n",
      "commercial\n",
      "commitment\n",
      "common\n",
      "commonly\n",
      "communicate\n",
      "communication\n",
      "community\n",
      "companies\n",
      "company\n",
      "comparable\n",
      "competencies\n",
      "competing\n",
      "competitive\n",
      "completion\n",
      "complex\n",
      "compliance\n",
      "component\n",
      "components\n",
      "composure\n",
      "comprehensive\n",
      "computational\n",
      "computer\n",
      "concepts\n",
      "conclusions\n",
      "condensate\n",
      "conditional\n",
      "conduct\n",
      "confidential\n",
      "config\n",
      "connect\n",
      "connecting\n",
      "consistency\n",
      "constant\n",
      "consultant\n",
      "consulting\n",
      "content\n",
      "continents\n",
      "continuous\n",
      "continuously\n",
      "contributor\n",
      "control\n",
      "convert\n",
      "converting\n",
      "cool\n",
      "coordinate\n",
      "corporate\n",
      "cpg\n",
      "create\n",
      "creating\n",
      "creation\n",
      "creative\n",
      "cross\n",
      "crossroads\n",
      "culture\n",
      "current\n",
      "d\n",
      "d3\n",
      "dash\n",
      "dashboard\n",
      "dashboards\n",
      "data\n",
      "database\n",
      "databases\n",
      "dataset\n",
      "datasets\n",
      "date\n",
      "db\n",
      "deadlines\n",
      "debug\n",
      "debugging\n",
      "decisions\n",
      "deep\n",
      "define\n",
      "defining\n",
      "definition\n",
      "degree\n",
      "deliver\n",
      "delivery\n",
      "demonstrable\n",
      "demonstrated\n",
      "dense\n",
      "departmental\n",
      "departments\n",
      "dependencies\n",
      "depending\n",
      "deploy\n",
      "deployed\n",
      "deploying\n",
      "deployment\n",
      "depth\n",
      "description\n",
      "descriptive\n",
      "design\n",
      "designing\n",
      "desired\n",
      "desktop\n",
      "detail\n",
      "detailed\n",
      "details\n",
      "detectron\n",
      "develop\n",
      "developer\n",
      "developing\n",
      "development\n",
      "devops\n",
      "dhabi\n",
      "diagnose\n",
      "different\n",
      "digital\n",
      "disciplinary\n",
      "discipline\n",
      "discovery\n",
      "discrepancies\n",
      "discretion\n",
      "distill\n",
      "distributed\n",
      "distribution\n",
      "diversity\n",
      "divestment\n",
      "django\n",
      "do\n",
      "dockerization\n",
      "doctoral\n",
      "documentation\n",
      "documenting\n",
      "documents\n",
      "domain\n",
      "domo\n",
      "dots\n",
      "draw\n",
      "driven\n",
      "duties\n",
      "dynamic\n",
      "e\n",
      "economic\n",
      "economics\n",
      "education\n",
      "effective\n",
      "effectively\n",
      "effectiveness\n",
      "efficiency\n",
      "effort\n",
      "efforts\n",
      "eliminate\n",
      "enable\n",
      "enabling\n",
      "end\n",
      "endeavors\n",
      "energy\n",
      "engage\n",
      "engineer\n",
      "engineering\n",
      "engineers\n",
      "english\n",
      "enhance\n",
      "enhanced\n",
      "enhancements\n",
      "enhancing\n",
      "ensure\n",
      "ensuring\n",
      "environment\n",
      "environments\n",
      "equity\n",
      "essential\n",
      "etc\n",
      "european\n",
      "event\n",
      "events\n",
      "ex\n",
      "examined\n",
      "excel\n",
      "excellent\n",
      "execute\n",
      "execution\n",
      "exercise\n",
      "exhaustive\n",
      "existing\n",
      "experience\n",
      "experienced\n",
      "expert\n",
      "expertise\n",
      "explain\n",
      "exploration\n",
      "exposure\n",
      "extensive\n",
      "external\n",
      "extraction\n",
      "face\n",
      "facilitate\n",
      "facts\n",
      "faculty\n",
      "failures\n",
      "familiarity\n",
      "family\n",
      "fast\n",
      "fastapi\n",
      "feasibility\n",
      "feel\n",
      "few\n",
      "field\n",
      "fields\n",
      "finance\n",
      "financial\n",
      "fine\n",
      "fiscal\n",
      "five\n",
      "fix\n",
      "fixed\n",
      "flask\n",
      "flexible\n",
      "flow\n",
      "focus\n",
      "focused\n",
      "following\n",
      "for\n",
      "form\n",
      "formal\n",
      "formulate\n",
      "four\n",
      "framework\n",
      "frameworks\n",
      "freedom\n",
      "from\n",
      "full\n",
      "fully\n",
      "functional\n",
      "functions\n",
      "g\n",
      "gas\n",
      "gather\n",
      "gathering\n",
      "gcp\n",
      "ge\n",
      "gen\n",
      "generate\n",
      "generating\n",
      "generative\n",
      "genuine\n",
      "geographic\n",
      "geology\n",
      "ggplot2\n",
      "git\n",
      "give\n",
      "global\n",
      "good\n",
      "gooddata\n",
      "google\n",
      "governance\n",
      "graduate\n",
      "granting\n",
      "graph\n",
      "graphic\n",
      "graphics\n",
      "grid\n",
      "group\n",
      "groups\n",
      "growth\n",
      "guide\n",
      "handling\n",
      "hands\n",
      "has\n",
      "have\n",
      "haystack\n",
      "health\n",
      "hear\n",
      "high\n",
      "higher\n",
      "highly\n",
      "hoc\n",
      "how\n",
      "hr\n",
      "hub\n",
      "humanities\n",
      "i\n",
      "ideal\n",
      "ideas\n",
      "identifiable\n",
      "identify\n",
      "if\n",
      "illustrator\n",
      "immediate\n",
      "impact\n",
      "implement\n",
      "implementation\n",
      "implementing\n",
      "improve\n",
      "improvement\n",
      "in\n",
      "include\n",
      "includes\n",
      "including\n",
      "inclusion\n",
      "incumbent\n",
      "independently\n",
      "indesign\n",
      "indexes\n",
      "indexing\n",
      "individual\n",
      "industry\n",
      "inflexible\n",
      "influence\n",
      "infographic\n",
      "infographics\n",
      "information\n",
      "informational\n",
      "infrastructure\n",
      "ingestion\n",
      "initiated\n",
      "initiatives\n",
      "innovate\n",
      "input\n",
      "insights\n",
      "institutional\n",
      "insurance\n",
      "integrate\n",
      "integrated\n",
      "intellectual\n",
      "intelligence\n",
      "interaction\n",
      "interactive\n",
      "interconnected\n",
      "interfaces\n",
      "international\n",
      "interpersonal\n",
      "into\n",
      "invariably\n",
      "ipeds\n",
      "is\n",
      "issue\n",
      "issues\n",
      "it\n",
      "its\n",
      "java\n",
      "jeans\n",
      "jira\n",
      "job\n",
      "join\n",
      "judgment\n",
      "key\n",
      "knowledge\n",
      "knows\n",
      "kpi\n",
      "kpis\n",
      "kubernetes\n",
      "langchain\n",
      "languages\n",
      "large\n",
      "latest\n",
      "layout\n",
      "lead\n",
      "learn\n",
      "learning\n",
      "least\n",
      "level\n",
      "levels\n",
      "leverage\n",
      "liberal\n",
      "libraries\n",
      "life\n",
      "lifecycle\n",
      "like\n",
      "linkages\n",
      "list\n",
      "ll\n",
      "llamaindex\n",
      "llm\n",
      "logging\n",
      "logical\n",
      "logically\n",
      "logistics\n",
      "looker\n",
      "looking\n",
      "love\n",
      "machine\n",
      "macros\n",
      "maintain\n",
      "maintaining\n",
      "maintains\n",
      "maintenance\n",
      "major\n",
      "make\n",
      "making\n",
      "manage\n",
      "management\n",
      "managers\n",
      "managing\n",
      "mange\n",
      "manipulation\n",
      "manner\n",
      "manufacturing\n",
      "mapping\n",
      "market\n",
      "markets\n",
      "masterâ\n",
      "materials\n",
      "mathematics\n",
      "matplotlib\n",
      "meet\n",
      "meets\n",
      "metrics\n",
      "microservices\n",
      "microsoft\n",
      "mindset\n",
      "minimal\n",
      "minimum\n",
      "mining\n",
      "mission\n",
      "mitigate\n",
      "ml\n",
      "mlops\n",
      "mobility\n",
      "model\n",
      "modeling\n",
      "modelling\n",
      "models\n",
      "moderately\n",
      "modifying\n",
      "modules\n",
      "moeâ\n",
      "momentive\n",
      "monday\n",
      "more\n",
      "motivated\n",
      "motivation\n",
      "move\n",
      "ms\n",
      "multicultural\n",
      "multiple\n",
      "navigating\n",
      "necessary\n",
      "need\n",
      "needed\n",
      "needs\n",
      "neo4j\n",
      "network\n",
      "neural\n",
      "new\n",
      "nice\n",
      "nlp\n",
      "noise\n",
      "non\n",
      "nosql\n",
      "not\n",
      "numpy\n",
      "nyu\n",
      "nyuad\n",
      "nyuadâ\n",
      "nyuâ\n",
      "object\n",
      "objectives\n",
      "ocr\n",
      "of\n",
      "office\n",
      "offshore\n",
      "oil\n",
      "on\n",
      "one\n",
      "onetrust\n",
      "online\n",
      "open\n",
      "operationalization\n",
      "operations\n",
      "opex\n",
      "opportunities\n",
      "opportunity\n",
      "optimization\n",
      "optimize\n",
      "options\n",
      "or\n",
      "oracle\n",
      "orchestration\n",
      "organizational\n",
      "organizations\n",
      "organizing\n",
      "oriented\n",
      "other\n",
      "others\n",
      "our\n",
      "out\n",
      "outline\n",
      "output\n",
      "outstanding\n",
      "overall\n",
      "overload\n",
      "overseas\n",
      "oversee\n",
      "own\n",
      "paced\n",
      "package\n",
      "paddleocr\n",
      "pandas\n",
      "part\n",
      "participate\n",
      "particularly\n",
      "partner\n",
      "partners\n",
      "patterns\n",
      "pegaga\n",
      "people\n",
      "performance\n",
      "performing\n",
      "personal\n",
      "personally\n",
      "personnel\n",
      "perspective\n",
      "pertains\n",
      "petroleum\n",
      "photoshop\n",
      "piktochart\n",
      "pinecone\n",
      "pipeline\n",
      "pipelines\n",
      "pipelining\n",
      "pivotal\n",
      "pivoting\n",
      "planning\n",
      "platform\n",
      "platforms\n",
      "plotly\n",
      "plus\n",
      "portal\n",
      "position\n",
      "post\n",
      "power\n",
      "powerpoint\n",
      "practice\n",
      "practices\n",
      "preferably\n",
      "preferred\n",
      "preparation\n",
      "prepares\n",
      "preparing\n",
      "present\n",
      "presentation\n",
      "pressure\n",
      "pretrained\n",
      "pricing\n",
      "prior\n",
      "privacy\n",
      "proactive\n",
      "proactively\n",
      "problem\n",
      "problems\n",
      "procedures\n",
      "process\n",
      "processes\n",
      "processing\n",
      "product\n",
      "production\n",
      "productively\n",
      "productizing\n",
      "products\n",
      "professional\n",
      "proficiencies\n",
      "proficiency\n",
      "proficient\n",
      "program\n",
      "programming\n",
      "programs\n",
      "progress\n",
      "project\n",
      "projects\n",
      "proven\n",
      "provide\n",
      "providing\n",
      "publishing\n",
      "pursuit\n",
      "pyramid\n",
      "python\n",
      "pytorch\n",
      "qdrant\n",
      "qualifications\n",
      "quality\n",
      "qualtrics\n",
      "queries\n",
      "questioning\n",
      "questions\n",
      "quickly\n",
      "r\n",
      "re\n",
      "ready\n",
      "real\n",
      "records\n",
      "refactor\n",
      "regulations\n",
      "related\n",
      "relational\n",
      "relationship\n",
      "relevant\n",
      "reliability\n",
      "reliable\n",
      "report\n",
      "reporting\n",
      "reports\n",
      "represents\n",
      "reproducible\n",
      "requestors\n",
      "requests\n",
      "required\n",
      "requirement\n",
      "requirements\n",
      "research\n",
      "resolve\n",
      "resources\n",
      "responsibilities\n",
      "responsibility\n",
      "responsible\n",
      "rest\n",
      "results\n",
      "retail\n",
      "review\n",
      "risks\n",
      "role\n",
      "roles\n",
      "rotations\n",
      "rules\n",
      "run\n",
      "running\n",
      "s\n",
      "safety\n",
      "sales\n",
      "sas\n",
      "scada\n",
      "scala\n",
      "scalability\n",
      "scalable\n",
      "scale\n",
      "scenarios\n",
      "scheduling\n",
      "scholarly\n",
      "science\n",
      "sciences\n",
      "scientists\n",
      "scikit\n",
      "scope\n",
      "scorecard\n",
      "scripting\n",
      "scrum\n",
      "seamless\n",
      "search\n",
      "secure\n",
      "security\n",
      "seeking\n",
      "segmentation\n",
      "self\n",
      "semantic\n",
      "senior\n",
      "seniorâ\n",
      "sensitivity\n",
      "serve\n",
      "server\n",
      "serves\n",
      "service\n",
      "services\n",
      "setting\n",
      "setup\n",
      "seven\n",
      "several\n",
      "shanghai\n",
      "shape\n",
      "shaped\n",
      "sharing\n",
      "sheet\n",
      "sheets\n",
      "shift\n",
      "shiny\n",
      "shirt\n",
      "should\n",
      "significant\n",
      "similar\n",
      "simple\n",
      "site\n",
      "situations\n",
      "six\n",
      "skill\n",
      "skilled\n",
      "skills\n",
      "sla\n",
      "slas\n",
      "small\n",
      "social\n",
      "software\n",
      "solid\n",
      "solution\n",
      "solutions\n",
      "solve\n",
      "solved\n",
      "solving\n",
      "source\n",
      "sources\n",
      "sparse\n",
      "special\n",
      "specialist\n",
      "specifications\n",
      "spectrum\n",
      "spoken\n",
      "sql\n",
      "staff\n",
      "stages\n",
      "stakeholder\n",
      "stakeholders\n",
      "standards\n",
      "stata\n",
      "statements\n",
      "static\n",
      "statistical\n",
      "statistics\n",
      "status\n",
      "stay\n",
      "sticks\n",
      "strategies\n",
      "strategy\n",
      "streamlined\n",
      "strong\n",
      "structured\n",
      "structures\n",
      "student\n",
      "students\n",
      "studio\n",
      "subsurface\n",
      "succeed\n",
      "successful\n",
      "such\n",
      "suite\n",
      "superior\n",
      "superset\n",
      "support\n",
      "supporting\n",
      "survey\n",
      "surveymonkey\n",
      "surveys\n",
      "system\n",
      "systems\n",
      "t\n",
      "tableau\n",
      "tables\n",
      "take\n",
      "target\n",
      "tasks\n",
      "tax\n",
      "team\n",
      "teams\n",
      "technical\n",
      "techniques\n",
      "technologies\n",
      "technology\n",
      "tensorflow\n",
      "term\n",
      "terms\n",
      "terra\n",
      "tesseract\n",
      "test\n",
      "tested\n",
      "testing\n",
      "text\n",
      "that\n",
      "the\n",
      "their\n",
      "there\n",
      "they\n",
      "this\n",
      "those\n",
      "thought\n",
      "thoughts\n",
      "through\n",
      "time\n",
      "timeline\n",
      "timely\n",
      "to\n",
      "tools\n",
      "topics\n",
      "track\n",
      "trained\n",
      "training\n",
      "transformative\n",
      "translate\n",
      "translated\n",
      "translating\n",
      "transparency\n",
      "trello\n",
      "trends\n",
      "troubleshoot\n",
      "tuning\n",
      "two\n",
      "typically\n",
      "under\n",
      "undergraduate\n",
      "understand\n",
      "understanding\n",
      "undertake\n",
      "units\n",
      "university\n",
      "unstructured\n",
      "up\n",
      "update\n",
      "updated\n",
      "us\n",
      "uscore\n",
      "use\n",
      "used\n",
      "user\n",
      "users\n",
      "using\n",
      "validation\n",
      "valuable\n",
      "value\n",
      "values\n",
      "various\n",
      "vector\n",
      "venture\n",
      "verbal\n",
      "verifiability\n",
      "version\n",
      "very\n",
      "vision\n",
      "visme\n",
      "visualization\n",
      "visualizations\n",
      "visuals\n",
      "vlookup\n",
      "volumes\n",
      "wams\n",
      "we\n",
      "web\n",
      "website\n",
      "welcomed\n",
      "well\n",
      "weviate\n",
      "when\n",
      "where\n",
      "which\n",
      "why\n",
      "wide\n",
      "will\n",
      "with\n",
      "within\n",
      "word\n",
      "work\n",
      "workflows\n",
      "working\n",
      "world\n",
      "wrike\n",
      "write\n",
      "written\n",
      "year\n",
      "years\n",
      "yolo\n",
      "york\n",
      "you\n",
      "your\n",
      "youâ\n",
      "â\n"
     ]
    }
   ],
   "source": [
    "# Define a regex pattern to find words (case insensitive)\n",
    "regex = r'\\b\\w+\\b'  # Matches any word\n",
    "\n",
    "# Find all words in the text using regex\n",
    "words = re.findall(regex, fh.lower())  # Convert to lowercase for uniform counting\n",
    "\n",
    "# Use a set to find unique words\n",
    "unique_words = set(words)\n",
    "\n",
    "# Print the unique words\n",
    "print(\"Unique Words:\")\n",
    "for word in sorted(unique_words):  # Sort for better readability\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from re import search\n",
    "from re import findall\n",
    "from re import split\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched\n"
     ]
    }
   ],
   "source": [
    "fh= open(r\"jobs-JDs.txt\",\"r\").read()\n",
    "match = search ('(skill)',fh)\n",
    "if match:\n",
    "    print(\"matched\")\n",
    "else:\n",
    "    print(\"no match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
